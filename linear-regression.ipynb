{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting BigMart Sales\n",
    "Provided by Analytics Vidhya, we have been participating in the BigMart Sales Practice Problem which began on May 25th, 2016, and ends on December 31st, 2018. Data scientists at BigMart have “collected 2013 sales data for 1559 products across 10 stores in different cities”, which participants will use to build a model to predict product sales by store. With this, BigMart will try to gain understanding of product and store properties that lead to increased sales.\n",
    "\n",
    "Using data to increase profitability is now an intuitive and common practice in business; the type, number, and even physical placement of products is no longer arbitrary, rather, it is determined by data. Therefore, this study echoes the common business approach to increasing profitability: data-driven decision making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Problem Statement**: “The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store. Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing sales.”_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Questions\n",
    "### What we are trying to learn:\n",
    "1. What properties of store are key in determining store profitability?\n",
    "2. What properties of products are key in determining product profitability?\n",
    "3. What products are most profitable in each location?\n",
    "    What category of products are most profitable in each location?\n",
    "5. What types of location are most profitable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific hypotheses we will be testing:\n",
    "\n",
    "This is our initial list of hypotheses we planned to test:\n",
    "1. Item visibility affects the sale of the product\n",
    "    Ex: the more exposed the item, the more sales it produces\n",
    "2. Outlet size and outlet location type affects the profitability of a store\n",
    " Ex: the larger the store, the more profits\n",
    "3. Profitability of a store is dependent on the product(s) it offers and its location\n",
    "4. Item that is placed at bigger shelf or shelf with height of average people is more likely catch customers’ attention and thus should have more sales\n",
    "5. Outlet with longer history is more likely to have higher profitability because it has impacted for the area for longer time\n",
    "6. Stores that are located in tier 1 cities or urban areas should have higher sales because people who live in these areas tend to have higher levels of income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After further inspection of the structure of the data, we must exclude some of them. Below shows our final hypotheses included in the analysis:\n",
    "\n",
    "1. Item visibility affects the sale of the product\n",
    "2. Outlet size and outlet location type affects the profitability of a store\n",
    "3. Hypothesis 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include required visualizations for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Info\n",
    "As mentioned above, the data for this challenge was collected and provided to participants by BigMart. Data scientists at BigMart “collected 2013 sales data for 1559 products across 10 stores in different cities.” Store and product include defined attributes, such as ID’s, category type, visibility, etc. The training dataset has 8,523 rows, and testing dataset has 5,681 rows. The training data has both input and output variables. Our task is to predict the sales for the testing dataset.\n",
    "\n",
    "** -Any important features on the dataset that are worth mentioning? Problems/bias with something?-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "We will first start with baseline model, which requires no prediction. We simply calculate mean values for a given category and compare with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will try linear regression model if both dependent and independent variables we are interested in are continuous and can fit linear regression well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use decision tree model to predict sales. The data it split into testing and training. This allows us to train our program with training data and then test our program with testing data. We will keep adjusting predictors to find the point when the program has the highest accuracy predicting sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just including decision tree? Or are we including all the models we have submitted and compare w/ visuals like a4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "-Include future steps-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to notebook 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualiation\n",
    "import urllib.request # to load data\n",
    "from scipy import stats # ANOVA\n",
    "from scipy.stats import ttest_ind # t-tests\n",
    "import statsmodels.formula.api as smf # linear modeling\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline \n",
    "\n",
    "%run linear_regression_helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "# %run data-prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(train_features.shape)\n",
    "# print(train_outcome.shape)\n",
    "# print(test_features.shape)\n",
    "# train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
